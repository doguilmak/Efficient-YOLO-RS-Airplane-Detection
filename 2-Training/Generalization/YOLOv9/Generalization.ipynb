{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "o5fqOgKeWKX0",
        "AQTm_EOwWQGB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Generalization with CORS-ADD-HBB Data**\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/RSandAI/Comprehensive-YOLO-Airplane-Detection/blob/main/assets/image.png\" height=450 width=1280 alt=\"\"/>\n",
        "</p>\n",
        "\n",
        "<small>Picture Source: <a href=\"https://github.com/RSandAI/Comprehensive-YOLO-Airplane-Detection/\">RSandAI, Comprehensive YOLO Airplane Detection</a></small>\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "SlPhpyI6HS7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Context**\n",
        "\n",
        "The HRPlanes dataset is a valuable resource in the domain of computer vision, particularly for tasks related to object detection, specifically focusing on aircraft within Very High Resolution (VHR) Google Earth images. This dataset comprises 3101 RGB images of major airports and aircraft boneyards, manually annotated with bounding boxes for airplanes using Plainsight (formerly HyperLabel). Quality control was conducted independently, resulting in 18,477 annotated airplanes. The dataset is split into 70% training (2170 images), 20% validation (620 images), and 10% testing (311 images) sets.\n",
        "\n",
        "<br>\n",
        "\n",
        "To facilitate accurate training and evaluation, each aircraft within the images has been meticulously labeled, resulting in a comprehensive annotation set covering a total of 18,477 aircraft instances. These annotations provide bounding box coordinates for each detected aircraft within the corresponding images.\n",
        "\n",
        "<br>\n",
        "\n",
        "## **Generalization with CORS-ADD-HBB Data**\n",
        "\n",
        "Generalization, the ability of a machine learning model to perform well on unseen data, is a critical aspect of model evaluation. In this study, we aim to assess the generalization performance of our top 2 YOLOv9 models using the CORS-ADD-HBB dataset. The CORS-ADD-HBB dataset, a curated collection of diverse data points, offers a comprehensive testbed for evaluating model robustness and adaptability across various domains. Leveraging this dataset, we seek to explore the extent to which our YOLOv9 models can effectively generalize beyond their training data, providing insights into their real-world applicability and reliability."
      ],
      "metadata": {
        "id": "5rgQR5X7HRYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top 3 Models:**\n",
        "\n",
        "| Rank | Experiment ID | Model | Network size | Optimizer | Augmentation | F1 Score | Precision | Recall | mAP50 | mAP50-95 |\n",
        "|--|--|--|--|--|--|--|--|--|--|--|\n",
        "| 1 | 58 | YOLOv9e | 640x640 | SGD | Hue (0.015) - Saturation (0.7) - Value (0.4) - Mosaic | 0.9917 | 0.9918 | 0.9916 | 0.9937 | 0.8989 |\n",
        "| 2 | 57 | YOLOv9e | 640x640 | SGD | None | 0.9899 | 0.9912 | 0.9886 | 0.9935 | 0.8982 |\n",
        "| 3 | 62 | YOLOv9e | 640x640 | ADAMW | Hue (0.015) - Saturation (0.7) - Value (0.4) - Mosaic | 0.9899 | 0.9891 | 0.9907 | 0.9936 | 0.8930 |\n",
        "\n",
        "<br>\n",
        "\n",
        "Make sure your runtime is **GPU** (_not_ CPU or TPU). And if it is an option, make sure you are using _Python 3_. You can select these settings by going to `Runtime -> Change runtime type -> Select the above mentioned settings and then press SAVE`."
      ],
      "metadata": {
        "id": "ugXS8sPHtd7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **0. Initial Steps**"
      ],
      "metadata": {
        "id": "Uu7E5OCcH5SP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **0.1 Download Library**"
      ],
      "metadata": {
        "id": "o5fqOgKeWKX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov9.git\n",
        "%cd yolov9\n",
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "id": "HvzVM57-Czws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ada828-71ed-49e6-b08d-5cd27c930f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov9'...\n",
            "remote: Enumerating objects: 781, done.\u001b[K\n",
            "remote: Total 781 (delta 0), reused 0 (delta 0), pack-reused 781 (from 1)\u001b[K\n",
            "Receiving objects: 100% (781/781), 3.27 MiB | 9.07 MiB/s, done.\n",
            "Resolving deltas: 100% (331/331), done.\n",
            "/content/yolov9\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **0.2. Import Libraries and Connect Google Drive**"
      ],
      "metadata": {
        "id": "AQTm_EOwWQGB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCgFeqUMAJKz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10736a82-546c-4c36-be52-55a8a761039e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "0DBKCj2i0wT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **0.3. Define Paths of Model Weights**"
      ],
      "metadata": {
        "id": "WCYpMXZATGxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ---\n",
        "\n",
        "MODEL_1_PT = '/gdrive/MyDrive/Datasets/HRPlanes/YOLOV8/YOLOv9e/Experiment_No_58/epoch_75_100/runs/train/exp/weights/best.pt' # @param {type:\"string\"}\n",
        "MODEL_2_PT = '/gdrive/MyDrive/Datasets/HRPlanes/YOLOV8/YOLOv9e/Experiment_No_57/runs/train/exp/weights/best.pt' # @param {type:\"string\"}\n",
        "MODEL_3_PT = '/gdrive/MyDrive/Datasets/HRPlanes/YOLOV8/YOLOv9e/Experiment_No_62/epoch_75_100/runs/train/exp/weights/best.pt' # @param {type:\"string\"}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lf0vAyvupf2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Validate Models with CORS-ADD-HBB Data**"
      ],
      "metadata": {
        "id": "8k2tR_67YGhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The T4 GPU is a powerful graphics processing unit (GPU) developed by NVIDIA. It is part of the NVIDIA Ampere architecture and is designed for high-performance computing tasks, including deep learning, data analytics, and scientific computing. The T4 GPU offers significant improvements in performance and efficiency compared to previous GPU models, making it ideal for demanding AI and machine learning applications."
      ],
      "metadata": {
        "id": "m40yO1p4WpAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "lcPubQct0hiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44abd07-197f-47f5-86ac-86e638f9cc03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 11 10:14:04 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1. Validate Model 1**"
      ],
      "metadata": {
        "id": "LojCdFYabrWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python val_dual.py \\\n",
        "--img 640 --batch 16 \\\n",
        "--data /content/coco_test.yaml \\\n",
        "--weights {MODEL_1_PT}"
      ],
      "metadata": {
        "id": "IEP1I_muYIHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a965f588-7ae3-446b-886b-af71cba84743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval_dual: \u001b[0mdata=/content/coco_test.yaml, weights=['/gdrive/MyDrive/Datasets/HRPlanes/YOLOV8/YOLOv9e/Experiment_No_58/epoch_75_100/runs/train/exp/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False, min_items=0\n",
            "YOLO üöÄ v0.1-104-g5b1ea9a Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "yolov9-e summary: 839 layers, 68547814 parameters, 0 gradients, 240.7 GFLOPs\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 43.2MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /gdrive/.shortcut-targets-by-id/1vm60fy0ismvMuhLfvW5phF0J1b9OKLLf/HRPlanes/YOLOV8/CORS_AD_HBB/val/labels.cache... 1722 images, 0 backgrounds, 0 corrupt: 100% 1722/1722 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 108/108 [03:14<00:00,  1.80s/it]\n",
            "                   all       1722       7769     0.9073     0.7428     0.8158     0.4188\n",
            "Speed: 0.3ms pre-process, 76.5ms inference, 1.9ms NMS per image at shape (16, 3, 640, 640)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[       5876         351]\n",
            " [       1893           0]]\n",
            "Results saved to \u001b[1mruns/val/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2. Validate Model 2**"
      ],
      "metadata": {
        "id": "nVty3iE-YHtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python val_dual.py \\\n",
        "--img 640 --batch 16 \\\n",
        "--data /content/coco_test.yaml \\\n",
        "--weights {MODEL_2_PT}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-YMllY5YHtg",
        "outputId": "0255d5cd-8c39-4943-8b8a-8d8ca8d98cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval_dual: \u001b[0mdata=/content/coco_test.yaml, weights=['/gdrive/MyDrive/Datasets/HRPlanes/YOLOV8/YOLOv9e/Experiment_No_57/runs/train/exp/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False, min_items=0\n",
            "YOLO üöÄ v0.1-104-g5b1ea9a Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "yolov9-e summary: 839 layers, 68547814 parameters, 0 gradients, 240.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /gdrive/.shortcut-targets-by-id/1vm60fy0ismvMuhLfvW5phF0J1b9OKLLf/HRPlanes/YOLOV8/CORS_AD_HBB/val/labels.cache... 1722 images, 0 backgrounds, 0 corrupt: 100% 1722/1722 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 108/108 [02:42<00:00,  1.51s/it]\n",
            "                   all       1722       7769      0.903     0.7355     0.8413     0.4486\n",
            "Speed: 0.3ms pre-process, 78.9ms inference, 1.5ms NMS per image at shape (16, 3, 640, 640)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[       5688         306]\n",
            " [       2081           0]]\n",
            "Results saved to \u001b[1mruns/val/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3. Validate Model 3**"
      ],
      "metadata": {
        "id": "NGwYfo1Ah_eC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python val_dual.py \\\n",
        "--img 640 --batch 16 \\\n",
        "--data /content/coco_test.yaml \\\n",
        "--weights {MODEL_3_PT}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKE-T9h6iBdc",
        "outputId": "10f993d2-9df2-43ef-e1b0-85f08bdaa089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval_dual: \u001b[0mdata=/content/coco_test.yaml, weights=['/gdrive/MyDrive/Datasets/HRPlanes/YOLOV8/YOLOv9e/Experiment_No_62/epoch_75_100/runs/train/exp/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False, min_items=0\n",
            "YOLO üöÄ v0.1-104-g5b1ea9a Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "/content/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "yolov9-e summary: 839 layers, 68547814 parameters, 0 gradients, 240.7 GFLOPs\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 44.7MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /gdrive/.shortcut-targets-by-id/1vm60fy0ismvMuhLfvW5phF0J1b9OKLLf/HRPlanes/YOLOV8/CORS_AD_HBB/val/labels... 1722 images, 0 backgrounds, 0 corrupt: 100% 1722/1722 [12:13<00:00,  2.35it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /gdrive/.shortcut-targets-by-id/1vm60fy0ismvMuhLfvW5phF0J1b9OKLLf/HRPlanes/YOLOV8/CORS_AD_HBB/val/labels.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 108/108 [02:24<00:00,  1.34s/it]\n",
            "                   all       1722       7769     0.8909     0.7419     0.8127     0.3974\n",
            "Speed: 0.3ms pre-process, 75.8ms inference, 1.5ms NMS per image at shape (16, 3, 640, 640)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[       5871         455]\n",
            " [       1898           0]]\n",
            "Results saved to \u001b[1mruns/val/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Move Model Items into Google Drive**"
      ],
      "metadata": {
        "id": "bIPMTw3c9BV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of uploading and downloading files, we can directly move them to the desired path."
      ],
      "metadata": {
        "id": "XE7YR2zw9DMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.move(\"/content/yolov9/runs/val/\", \"/gdrive/MyDrive/Datasets/HRPlanes/YOLOV8/CORS_AD_HBB/YOLOv9 Tests/\")"
      ],
      "metadata": {
        "id": "oNDkAwhe9B-9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4ff812be-8377-43db-8b9b-f8100011b1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/gdrive/MyDrive/Datasets/HRPlanes/YOLOV8/CORS_AD_HBB/YOLOv9 Tests/val'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "print(f\"Changes have been made to the project on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ],
      "metadata": {
        "id": "E6YQF5c39FKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aef7749-1a9e-4229-a98e-5735f3997276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changes have been made to the project on 2024-09-11 10:36:03\n"
          ]
        }
      ]
    }
  ]
}